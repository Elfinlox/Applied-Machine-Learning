{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc57c32",
   "metadata": {},
   "source": [
    "# Assignment 1 - Applied Machine Learning\n",
    "---\n",
    "## Arghadeep Ghosh\n",
    "\n",
    "This notebook 'train.csv' contains the code for loading the Training, Validation and Test datasets, fitting Naive-Bayes, Logistic Regression and Random Forest models on the training data and evaluating the model on the Validation and Test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5953b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd3e540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 1115, 1115)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "valid = pd.read_csv('data/validation.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dd9be",
   "metadata": {},
   "source": [
    "## Preprocessing Functions\n",
    "---\n",
    "The data is converted from a sentence model to a Bag of words format with each word asigned a tf-idf weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3eefbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [going, for, dinner.msg, you, after]\n",
       "1       [please, call, 08712402578, immediately, a, th...\n",
       "2       [am, only, searching, for, good, dual, sim, mo...\n",
       "3                       [ya, that, one, is, slow, a, poo]\n",
       "4                      [talk, to, g, and, x, about, that]\n",
       "                              ...                        \n",
       "3339    [iÂ’m, cool, ta, luv, but, v.tired, 2, cause, i...\n",
       "3340                   [4, taco, 1, raja, burrito, right]\n",
       "3341    [ma, head, dey, swell, oh, thanks, for, making...\n",
       "3342    [yes, the, only, place, in, town, to, meet, ex...\n",
       "3343       [i, 'm, good, have, you, registered, to, vote]\n",
       "Name: message, Length: 3344, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message = message.lower()  # convert bytes into proper unicode\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "train.message.apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037b9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(train['message'])\n",
    "train_bow = bow_transformer.transform(train['message'])\n",
    "valid_bow = bow_transformer.transform(valid['message'])\n",
    "test_bow = bow_transformer.transform(test['message'])\n",
    "\n",
    "bow = bow_transformer.transform([train['message'][5]])\n",
    "\n",
    "print(bow_transformer.get_feature_names_out()[2096])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f37aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6454)\t0.22971346003428875\n",
      "  (0, 6400)\t0.11771610046219375\n",
      "  (0, 6046)\t0.1579552939608168\n",
      "  (0, 5923)\t0.1945482280959502\n",
      "  (0, 5836)\t0.10090471982516318\n",
      "  (0, 5797)\t0.19832567147753144\n",
      "  (0, 5697)\t0.07860951998278148\n",
      "  (0, 5637)\t0.13830934410443585\n",
      "  (0, 4477)\t0.18313084909544983\n",
      "  (0, 4151)\t0.16752358524628597\n",
      "  (0, 4091)\t0.12427382764296355\n",
      "  (0, 3966)\t0.1377534794481989\n",
      "  (0, 3763)\t0.17014811410617742\n",
      "  (0, 3345)\t0.2193993235307073\n",
      "  (0, 3116)\t0.1080116708513791\n",
      "  (0, 2522)\t0.1412257928846768\n",
      "  (0, 2378)\t0.24802786234704557\n",
      "  (0, 1687)\t0.19279897619093267\n",
      "  (0, 1403)\t0.24425041896546437\n",
      "  (0, 1389)\t0.11835255301240706\n",
      "  (0, 1268)\t0.3019528756441539\n",
      "  (0, 1233)\t0.2348439904928211\n",
      "  (0, 1020)\t0.21139905772153192\n",
      "  (0, 486)\t0.3019528756441539\n",
      "  (0, 281)\t0.21286263040870704\n",
      "  (0, 185)\t0.3019528756441539\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(train_bow)\n",
    "train_tfidf = tfidf_transformer.transform(train_bow)\n",
    "valid_tfidf = tfidf_transformer.transform(valid_bow)\n",
    "test_tfidf = tfidf_transformer.transform(test_bow)\n",
    "\n",
    "\n",
    "tfidf = tfidf_transformer.transform(bow)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23fd331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y):\n",
    "    Y_pred = model.predict(X)\n",
    "\n",
    "    print('Accuracy:', accuracy_score(Y, Y_pred)*100, '%')\n",
    "    print('Precision:', precision_score(Y, Y_pred, pos_label = 'spam')*100, '%')\n",
    "    print('Recall:', recall_score(Y, Y_pred, pos_label = 'spam')*100, '%')\n",
    "    print('F1 Score:', f1_score(Y, Y_pred, pos_label = 'spam')*100, '%')\n",
    "\n",
    "    cm = confusion_matrix(Y, Y_pred)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac88d76",
   "metadata": {},
   "source": [
    "## Naive-Bayes Model\n",
    "---\n",
    "We train Multinomial Naive-Bayes models on the training data for different values of alpha and evaluate it on the validation and testing data. We've obtained the Accuracy, precision, recall, F1 score and AUPCR in each case.\n",
    "\n",
    "All the metrics and parameters are tracked using mlflow and the runtime can be seen by running\n",
    "```> mlflow ui```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6435ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Argodep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "for alpha in np.arange(0.2, 2.0, 0.3):\n",
    "    with mlflow.start_run():\n",
    "        spam_detectorNB = MultinomialNB(alpha = alpha).fit(train_tfidf, train['label'])\n",
    "        \n",
    "        Y_pred = (spam_detectorNB.predict(train_tfidf) == 'spam').astype('int64')\n",
    "        Y = (train['label'] == 'spam').astype('int64')\n",
    "\n",
    "        acc = accuracy_score(Y, Y_pred)    \n",
    "        pres = precision_score(Y, Y_pred)\n",
    "        rec = recall_score(Y, Y_pred)\n",
    "        f1 = f1_score(Y, Y_pred)\n",
    "        \n",
    "        p, r, threshold = precision_recall_curve(Y, Y_pred)\n",
    "        aucpr = auc(p, r)\n",
    "\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_metric(\"acc\", acc)\n",
    "        mlflow.log_metric(\"pres\", pres)\n",
    "        mlflow.log_metric(\"rec\", rec)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        if tracking_url_type_store != \"file\":\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\", registered_model_name=\"NaiveBayes\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc8e85",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "---\n",
    "We train Logistic Regression models on the training data for different C values and evaluate it on the validation and testing data. We've obtained the Accuracy, precision, recall, F1 score and AUCPR in each case.\n",
    "\n",
    "All the metrics and parameters are tracked using mlflow and the runtime can be seen by running\n",
    "```> mlflow ui```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4700c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "Cs = [0.1, 0.5, 1, 10, 20, 50, 100]\n",
    "for C in Cs:\n",
    "    with mlflow.start_run():\n",
    "        spam_detectorLR = LogisticRegression(C = C).fit(train_tfidf, train['label'])\n",
    "        \n",
    "        Y_pred = (spam_detectorLR.predict(train_tfidf) == 'spam').astype('int64')\n",
    "        Y = (train['label'] == 'spam').astype('int64')\n",
    "\n",
    "        acc = accuracy_score(Y, Y_pred)    \n",
    "        pres = precision_score(Y, Y_pred)\n",
    "        rec = recall_score(Y, Y_pred)\n",
    "        f1 = f1_score(Y, Y_pred)\n",
    "        \n",
    "        p, r, threshold = precision_recall_curve(Y, Y_pred)\n",
    "        aucpr = auc(p, r)\n",
    "\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_metric(\"acc\", acc)\n",
    "        mlflow.log_metric(\"pres\", pres)\n",
    "        mlflow.log_metric(\"rec\", rec)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        if tracking_url_type_store != \"file\":\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\", registered_model_name=\"NaiveBayes\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f863c",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "---\n",
    "\n",
    "We train Random Forest models on the training data for different values of n estimators and evaluate it on the validation and testing data. We've obtained the Accuracy, precision, recall, F1 score and AUCPR in each case.\n",
    "\n",
    "All the metrics and parameters are tracked using mlflow and the runtime can be seen by running\n",
    "```> mlflow ui```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f62ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "for n in range(10, 100, 10):\n",
    "    with mlflow.start_run():\n",
    "        spam_detectorRF = RandomForestClassifier(n_estimators = n).fit(train_tfidf, train['label'])\n",
    "        \n",
    "        Y_pred = (spam_detectorRF.predict(train_tfidf) == 'spam').astype('int64')\n",
    "        Y = (train['label'] == 'spam').astype('int64')\n",
    "\n",
    "        acc = accuracy_score(Y, Y_pred)    \n",
    "        pres = precision_score(Y, Y_pred)\n",
    "        rec = recall_score(Y, Y_pred)\n",
    "        f1 = f1_score(Y, Y_pred)\n",
    "        \n",
    "        p, r, threshold = precision_recall_curve(Y, Y_pred)\n",
    "        aucpr = auc(p, r)\n",
    "\n",
    "        mlflow.log_param(\"n trees\", n)\n",
    "        mlflow.log_metric(\"acc\", acc)\n",
    "        mlflow.log_metric(\"pres\", pres)\n",
    "        mlflow.log_metric(\"rec\", rec)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        if tracking_url_type_store != \"file\":\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\", registered_model_name=\"NaiveBayes\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(spam_detectorNB, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
